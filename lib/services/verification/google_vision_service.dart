// lib/services/verification/google_vision_service.dart

import 'dart:convert';
import 'package:http/http.dart' as http;
import 'package:file_selector/file_selector.dart';
import '../../services/config/api_config.dart';

class GoogleVisionService {
  
  /// Analyser un document avec Google Vision API
  static Future<DocumentAnalysisResult> analyzeDocument(XFile file) async {
    try {
      // V√©rifier la configuration
      if (!(await ApiConfig.isGoogleVisionConfigured)) {
        throw Exception('Google Vision API non configur√©e');
      }
      
      print('üîç Analyse du document avec Google Vision...');
      
      // 1. Lire et encoder le fichier
      final bytes = await file.readAsBytes();
      final base64Image = base64Encode(bytes);
      
      // 2. Pr√©parer la requ√™te avec plus de features pour une meilleure d√©tection
      final request = {
        'requests': [
          {
            'image': {
              'content': base64Image,
            },
            'features': [
              {
                'type': 'DOCUMENT_TEXT_DETECTION',
                'maxResults': 50,
              },
              {
                'type': 'OBJECT_LOCALIZATION',
                'maxResults': 10,
              },
              // Ajout pour une meilleure d√©tection des logos et √©l√©ments officiels
              {
                'type': 'LOGO_DETECTION',
                'maxResults': 5,
              },
            ],
          }
        ],
      };
      
      // 3. Appeler Google Vision API
      final apiKey = await ApiConfig.googleVisionApiKey;
      final response = await http.post(
        Uri.parse('${ApiConfig.googleVisionBaseUrl}/images:annotate?key=$apiKey'),
        headers: {
          'Content-Type': 'application/json',
        },
        body: jsonEncode(request),
      );
      
      if (response.statusCode != 200) {
        throw Exception('Erreur Google Vision API: ${response.statusCode} - ${response.body}');
      }
      
      // 4. Parser la r√©ponse
      final data = jsonDecode(response.body);
      final responses = data['responses'] as List;
      
      if (responses.isEmpty) {
        throw Exception('Aucune r√©ponse de Google Vision');
      }
      
      final firstResponse = responses[0];
      
      // V√©rifier les erreurs
      if (firstResponse['error'] != null) {
        throw Exception('Erreur API: ${firstResponse['error']['message']}');
      }
      
      // 5. Extraire les donn√©es
      final result = _parseVisionResponse(firstResponse, file.name, bytes.length);
      
      print('‚úÖ Analyse termin√©e: ${result.documentType} (${result.confidence.toStringAsFixed(2)})');
      
      return result;
      
    } catch (e) {
      print('‚ùå Erreur analyse document: $e');
      return DocumentAnalysisResult.error(e.toString());
    }
  }
  
  /// Parser la r√©ponse de Google Vision
  static DocumentAnalysisResult _parseVisionResponse(
    Map<String, dynamic> response, 
    String filename, 
    int fileSize,
  ) {
    // Extraire le texte
    String extractedText = '';
    if (response['fullTextAnnotation'] != null) {
      extractedText = response['fullTextAnnotation']['text'] ?? '';
    }
    
    // Analyser les objets d√©tect√©s
    final objects = response['localizedObjectAnnotations'] as List? ?? [];
    final hasPhoto = objects.any((obj) => 
      ['Person', 'Face', 'Human face'].contains(obj['name']));
    
    // Analyser les logos d√©tect√©s (pour documents officiels)
    final logos = response['logoAnnotations'] as List? ?? [];
    final hasOfficialLogo = logos.isNotEmpty;
    
    // Classifier le document selon les exigences KIPIK
    final classification = _classifyDocumentKIPIK(extractedText, filename, hasOfficialLogo);
    
    // V√©rifications sp√©cifiques
    final checks = _performKIPIKValidation(extractedText, filename, fileSize, classification.type);
    
    return DocumentAnalysisResult(
      documentType: classification.type,
      confidence: classification.confidence,
      extractedText: extractedText,
      hasPhoto: hasPhoto,
      hasSignature: _detectSignature(extractedText),
      fileSize: fileSize,
      language: _detectLanguage(extractedText),
      validationChecks: checks,
      recommendations: _generateKIPIKRecommendations(classification, checks),
      hasOfficialLogo: hasOfficialLogo,
    );
  }
  
  /// Classification optimis√©e pour les documents KIPIK
  static _DocumentType _classifyDocumentKIPIK(String text, String filename, bool hasOfficialLogo) {
    final normalizedText = text.toLowerCase().replaceAll('\n', ' ').replaceAll(RegExp(r'\s+'), ' ');
    final normalizedFilename = filename.toLowerCase();
    
    // Patterns optimis√©s pour les documents requis par KIPIK
    final patterns = {
      // PIECES D'IDENTIT√â (Particuliers, Pro, Orga)
      'carte_identite': {
        'keywords': [
          'carte nationale d\'identit√©',
          'carte d\'identit√©',
          'r√©publique fran√ßaise',
          'nationalit√© fran√ßaise',
          'n√©(e) le',
          'pr√©fecture',
          'minist√®re de l\'int√©rieur',
          'carte d\'identit√© fran√ßaise',
        ],
        'weight': 1.3,
        'required_count': 2, // Au moins 2 mots-cl√©s requis
      },
      'passeport': {
        'keywords': [
          'passeport',
          'passport',
          'union europ√©enne',
          'type p',
          'authority',
          'r√©publique fran√ßaise',
          'passeport fran√ßais',
          'french passport',
        ],
        'weight': 1.3,
        'required_count': 2,
      },
      
      // DOCUMENTS FINANCIERS (Tous types)
      'rib': {
        'keywords': [
          'relev√© d\'identit√© bancaire',
          'rib',
          'iban',
          'bic',
          'code banque',
          'domiciliation',
          'titulaire du compte',
          '√©tablissement',
        ],
        'weight': 1.2,
        'required_count': 2,
      },
      
      // DOCUMENTS PROFESSIONNELS (Pro et Orga uniquement)
      'kbis': {
        'keywords': [
          'extrait kbis',
          'k-bis',
          'registre du commerce',
          'rcs',
          'siren',
          'siret',
          'greffe',
          'capital social',
          'extrait du registre',
        ],
        'weight': 1.4, // Poids √©lev√© car tr√®s sp√©cifique
        'required_count': 2,
      },
      'certificat_hygiene': {
        'keywords': [
          'certificat',
          'hygi√®ne',
          'haccp',
          'formation',
          'salubrit√©',
          'agr√©√©',
          'validit√©',
          's√©curit√© alimentaire',
        ],
        'weight': 1.1,
        'required_count': 2,
      },
    };
    
    double maxScore = 0.0;
    String bestType = 'unknown';
    
    patterns.forEach((type, config) {
      final keywords = config['keywords'] as List<String>;
      final weight = config['weight'] as double;
      final requiredCount = config['required_count'] as int;
      
      int matches = 0;
      List<String> foundKeywords = [];
      
      for (final keyword in keywords) {
        if (normalizedText.contains(keyword) || normalizedFilename.contains(keyword)) {
          matches++;
          foundKeywords.add(keyword);
        }
      }
      
      // Score uniquement si on a le nombre minimum de mots-cl√©s
      if (matches >= requiredCount) {
        double score = (matches / keywords.length) * weight;
        
        // Bonus pour correspondance multiple
        if (matches > requiredCount) {
          score *= (1.0 + (matches - requiredCount) * 0.2);
        }
        
        // Bonus pour correspondance dans le nom de fichier
        bool filenameMatch = keywords.any((k) => normalizedFilename.contains(k));
        if (filenameMatch) {
          score *= 1.2;
        }
        
        if (score > maxScore) {
          maxScore = score;
          bestType = type;
        }
        
        print('üîç Type: $type, Matches: $matches/${keywords.length}, Score: ${score.toStringAsFixed(2)}, Mots trouv√©s: $foundKeywords');
      }
    });
    
    return _DocumentType(
      type: bestType,
      confidence: maxScore.clamp(0.0, 1.0),
    );
  }
  
  /// Validations sp√©cifiques KIPIK
  static List<ValidationCheck> _performKIPIKValidation(String text, String filename, int fileSize, String documentType) {
    final checks = <ValidationCheck>[];
    
    // 1. V√©rifications g√©n√©rales
    _addGeneralChecks(checks, fileSize, filename, text);
    
    // 2. V√©rifications sp√©cifiques par type de document
    switch (documentType) {
      case 'carte_identite':
        _addIdentityCardChecks(checks, text);
        break;
      case 'passeport':
        _addPassportChecks(checks, text);
        break;
      case 'rib':
        _addRIBChecks(checks, text);
        break;
      case 'kbis':
        _addKbisChecks(checks, text);
        break;
      case 'certificat_hygiene':
        _addHygieneChecks(checks, text);
        break;
    }
    
    return checks;
  }
  
  static void _addGeneralChecks(List<ValidationCheck> checks, int fileSize, String filename, String text) {
    // Taille du fichier
    if (fileSize < 100 * 1024) { // Moins de 100KB
      checks.add(ValidationCheck('file_size', false, 'Fichier trop petit (${(fileSize/1024).round()}KB) - Qualit√© insuffisante'));
    } else if (fileSize > 15 * 1024 * 1024) { // Plus de 15MB
      checks.add(ValidationCheck('file_size', false, 'Fichier trop volumineux (${(fileSize/(1024*1024)).round()}MB)'));
    } else {
      checks.add(ValidationCheck('file_size', true, 'Taille acceptable (${(fileSize/1024).round()}KB)'));
    }
    
    // Format de fichier
    final validExtensions = ['pdf', 'jpg', 'jpeg', 'png'];
    final extension = filename.split('.').last.toLowerCase();
    checks.add(ValidationCheck(
      'file_format', 
      validExtensions.contains(extension),
      validExtensions.contains(extension) ? 'Format valide: $extension' : 'Format non support√©: $extension',
    ));
    
    // Contenu textuel
    if (text.trim().isEmpty) {
      checks.add(ValidationCheck('text_content', false, 'Aucun texte d√©tect√© - Document illisible'));
    } else if (text.length < 30) {
      checks.add(ValidationCheck('text_content', false, 'Tr√®s peu de texte (${text.length} car.) - Qualit√© insuffisante'));
    } else {
      checks.add(ValidationCheck('text_content', true, 'Texte d√©tect√© (${text.length} caract√®res)'));
    }
  }
  
  static void _addIdentityCardChecks(List<ValidationCheck> checks, String text) {
    final normalizedText = text.toLowerCase();
    
    // √âl√©ments obligatoires d'une CNI
    final requiredElements = {
      'nom': ['nom', 'surname'],
      'prenom': ['pr√©nom', 'pr√©noms', 'given name'],
      'naissance': ['n√©(e) le', 'date of birth', 'birth'],
      'nationalite': ['nationalit√©', 'nationality', 'fran√ßaise'],
    };
    
    requiredElements.forEach((element, keywords) {
      bool found = keywords.any((k) => normalizedText.contains(k));
      checks.add(ValidationCheck(
        'cni_$element',
        found,
        found ? '‚úì $element d√©tect√©' : '‚úó $element manquant',
      ));
    });
  }
  
  // CORRECTION: Fonction _addPassportChecks corrig√©e
  static void _addPassportChecks(List<ValidationCheck> checks, String text) {
    final normalizedText = text.toLowerCase();
    
    // CORRECTION: Utiliser des listes coh√©rentes au lieu de types mixtes
    final typeKeywords = ['type p', 'passport'];
    final countryKeywords = ['fra', 'france'];
    final numeroRegex = RegExp(r'\d{2}[a-z]{2}\d{5}'); // Format num√©ro passeport fran√ßais
    
    bool hasType = typeKeywords.any((k) => normalizedText.contains(k));
    bool hasCountry = countryKeywords.any((k) => normalizedText.contains(k));
    bool hasNumber = numeroRegex.hasMatch(text);
    
    checks.add(ValidationCheck('passport_type', hasType, hasType ? '‚úì Type passeport d√©tect√©' : '‚úó Type passeport manquant'));
    checks.add(ValidationCheck('passport_country', hasCountry, hasCountry ? '‚úì Pays d√©tect√©' : '‚úó Pays manquant'));
    checks.add(ValidationCheck('passport_number', hasNumber, hasNumber ? '‚úì Num√©ro d√©tect√©' : '‚úó Format num√©ro invalide'));
  }
  
  static void _addRIBChecks(List<ValidationCheck> checks, String text) {
    final normalizedText = text.toLowerCase();
    
    // V√©rifications IBAN/BIC
    final ibanRegex = RegExp(r'fr\d{2}\s?\d{4}\s?\d{4}\s?\d{4}\s?\d{4}\s?\d{4}\s?\d{2}');
    final bicRegex = RegExp(r'[a-z]{4}fr[a-z0-9]{2}([a-z0-9]{3})?');
    
    bool hasIban = ibanRegex.hasMatch(normalizedText);
    bool hasBic = bicRegex.hasMatch(normalizedText) || normalizedText.contains('bic');
    bool hasTitulaire = normalizedText.contains('titulaire') || normalizedText.contains('account holder');
    
    checks.add(ValidationCheck('rib_iban', hasIban, hasIban ? '‚úì IBAN fran√ßais d√©tect√©' : '‚úó IBAN manquant ou invalide'));
    checks.add(ValidationCheck('rib_bic', hasBic, hasBic ? '‚úì BIC d√©tect√©' : '‚úó BIC manquant'));
    checks.add(ValidationCheck('rib_titulaire', hasTitulaire, hasTitulaire ? '‚úì Titulaire mentionn√©' : '‚úó Titulaire non mentionn√©'));
  }
  
  static void _addKbisChecks(List<ValidationCheck> checks, String text) {
    final normalizedText = text.toLowerCase();
    
    // V√©rifications sp√©cifiques KBIS
    final sirenRegex = RegExp(r'\d{9}');
    final siretRegex = RegExp(r'\d{14}');
    
    bool hasSiren = normalizedText.contains('siren') && sirenRegex.hasMatch(text);
    bool hasSiret = normalizedText.contains('siret') && siretRegex.hasMatch(text);
    bool hasGreffe = normalizedText.contains('greffe');
    bool hasRCS = normalizedText.contains('rcs') || normalizedText.contains('registre du commerce');
    
    // V√©rification de la date (KBIS de moins de 3 mois)
    bool hasRecentDate = _checkKbisDate(text);
    
    checks.add(ValidationCheck('kbis_siren', hasSiren, hasSiren ? '‚úì SIREN d√©tect√©' : '‚úó SIREN manquant'));
    checks.add(ValidationCheck('kbis_siret', hasSiret, hasSiret ? '‚úì SIRET d√©tect√©' : '‚úó SIRET manquant'));
    checks.add(ValidationCheck('kbis_greffe', hasGreffe, hasGreffe ? '‚úì Greffe mentionn√©' : '‚úó Greffe non mentionn√©'));
    checks.add(ValidationCheck('kbis_rcs', hasRCS, hasRCS ? '‚úì RCS d√©tect√©' : '‚úó RCS manquant'));
    checks.add(ValidationCheck('kbis_date', hasRecentDate, hasRecentDate ? '‚úì Date r√©cente' : '‚ö†Ô∏è V√©rifier la date (< 3 mois requis)'));
  }
  
  static void _addHygieneChecks(List<ValidationCheck> checks, String text) {
    final normalizedText = text.toLowerCase();
    
    bool hasCertificat = normalizedText.contains('certificat');
    bool hasHygiene = normalizedText.contains('hygi√®ne') || normalizedText.contains('haccp');
    bool hasValidite = normalizedText.contains('validit√©') || normalizedText.contains('valable');
    bool hasFormation = normalizedText.contains('formation') || normalizedText.contains('stage');
    
    checks.add(ValidationCheck('hygiene_certificat', hasCertificat, hasCertificat ? '‚úì Certificat d√©tect√©' : '‚úó Certificat non mentionn√©'));
    checks.add(ValidationCheck('hygiene_type', hasHygiene, hasHygiene ? '‚úì Type hygi√®ne d√©tect√©' : '‚úó Type non pr√©cis√©'));
    checks.add(ValidationCheck('hygiene_validite', hasValidite, hasValidite ? '‚úì Validit√© mentionn√©e' : '‚ö†Ô∏è V√©rifier la validit√©'));
    checks.add(ValidationCheck('hygiene_formation', hasFormation, hasFormation ? '‚úì Formation mentionn√©e' : '‚úó Formation non mentionn√©e'));
  }
  
  static bool _checkKbisDate(String text) {
    // Regex pour d√©tecter des dates r√©centes (approximatif)
    final dateRegex = RegExp(r'\d{1,2}/\d{1,2}/202[4-5]');
    return dateRegex.hasMatch(text);
  }
  
  /// D√©tecter la pr√©sence d'une signature
  static bool _detectSignature(String text) {
    final signatureIndicators = [
      'signature',
      'sign√©',
      'signed',
      'le titulaire',
      'signature du titulaire',
      'certifi√© conforme',
    ];
    
    final normalizedText = text.toLowerCase();
    return signatureIndicators.any((indicator) => normalizedText.contains(indicator));
  }
  
  /// D√©tecter la langue
  static String _detectLanguage(String text) {
    final frenchWords = ['le', 'la', 'les', 'de', 'du', 'et', '√†', 'r√©publique', 'fran√ßaise', 'pr√©fecture'];
    final normalizedText = text.toLowerCase();
    
    int frenchMatches = 0;
    for (final word in frenchWords) {
      if (normalizedText.contains(word)) {
        frenchMatches++;
      }
    }
    
    return frenchMatches >= 3 ? 'fr' : 'unknown';
  }
  
  /// G√©n√©rer des recommandations KIPIK
  static List<String> _generateKIPIKRecommendations(_DocumentType classification, List<ValidationCheck> checks) {
    final recommendations = <String>[];
    
    // Recommandations selon la confiance
    if (classification.confidence > 0.8) {
      recommendations.add('‚úÖ Document ${_getDocumentDisplayName(classification.type)} correctement identifi√©');
    } else if (classification.confidence > 0.5) {
      recommendations.add('‚ö†Ô∏è Document probablement un ${_getDocumentDisplayName(classification.type)} - V√©rification manuelle recommand√©e');
    } else {
      recommendations.add('‚ùå Type de document incertain - V√©rification manuelle obligatoire');
    }
    
    // Analyser les √©checs de validation
    final failedChecks = checks.where((check) => !check.passed).toList();
    final criticalFailed = failedChecks.where((check) => 
      check.type.contains('_content') || 
      check.type.contains('_format') || 
      check.type.contains('_size')
    ).toList();
    
    if (criticalFailed.isNotEmpty) {
      recommendations.add('üö´ ${criticalFailed.length} v√©rification(s) critique(s) √©chou√©e(s)');
    } else if (failedChecks.isNotEmpty) {
      recommendations.add('‚ö†Ô∏è ${failedChecks.length} v√©rification(s) secondaire(s) √† contr√¥ler');
    }
    
    // Recommandations sp√©cifiques par type
    _addTypeSpecificRecommendations(recommendations, classification.type, checks);
    
    return recommendations;
  }
  
  static void _addTypeSpecificRecommendations(List<String> recommendations, String type, List<ValidationCheck> checks) {
    switch (type) {
      case 'kbis':
        final dateCheck = checks.firstWhere((c) => c.type == 'kbis_date', orElse: () => ValidationCheck('', false, ''));
        if (!dateCheck.passed) {
          recommendations.add('üìÖ IMPORTANT: V√©rifier que le KBIS date de moins de 3 mois');
        }
        break;
      case 'certificat_hygiene':
        recommendations.add('‚è∞ V√©rifier la date de validit√© du certificat');
        break;
      case 'carte_identite':
      case 'passeport':
        recommendations.add('üì∏ V√©rifier la pr√©sence de la photo et la lisibilit√©');
        break;
    }
  }
  
  static String _getDocumentDisplayName(String type) {
    const displayNames = {
      'carte_identite': 'Carte d\'identit√©',
      'passeport': 'Passeport',
      'rib': 'Relev√© d\'identit√© bancaire (RIB)',
      'kbis': 'Extrait KBIS',
      'certificat_hygiene': 'Certificat d\'hygi√®ne et salubrit√©',
      'unknown': 'Document non identifi√©',
    };
    return displayNames[type] ?? type;
  }
}

/// R√©sultat de l'analyse optimis√©
class DocumentAnalysisResult {
  final String documentType;
  final double confidence;
  final String extractedText;
  final bool hasPhoto;
  final bool hasSignature;
  final int fileSize;
  final String language;
  final List<ValidationCheck> validationChecks;
  final List<String> recommendations;
  final bool isError;
  final String? errorMessage;
  final bool hasOfficialLogo;
  
  DocumentAnalysisResult({
    required this.documentType,
    required this.confidence,
    required this.extractedText,
    required this.hasPhoto,
    required this.hasSignature,
    required this.fileSize,
    required this.language,
    required this.validationChecks,
    required this.recommendations,
    this.isError = false,
    this.errorMessage,
    this.hasOfficialLogo = false,
  });
  
  factory DocumentAnalysisResult.error(String error) {
    return DocumentAnalysisResult(
      documentType: 'error',
      confidence: 0.0,
      extractedText: '',
      hasPhoto: false,
      hasSignature: false,
      fileSize: 0,
      language: 'unknown',
      validationChecks: [],
      recommendations: ['Erreur: $error'],
      isError: true,
      errorMessage: error,
    );
  }
  
  /// Action recommand√©e selon les crit√®res KIPIK
  String get recommendedAction {
    if (isError) return 'ERROR';
    
    final criticalFailed = validationChecks.where((check) => 
      !check.passed && (
        check.type.contains('file_size') || 
        check.type.contains('file_format') || 
        check.type.contains('text_content')
      )
    ).toList();
    
    if (criticalFailed.isNotEmpty) {
      return 'REJECT';
    }
    
    if (confidence > 0.8 && validationChecks.where((c) => !c.passed).length <= 2) {
      return 'AUTO_APPROVE';
    } else if (confidence > 0.5) {
      return 'MANUAL_REVIEW';
    } else {
      return 'REJECT';
    }
  }
  
  /// V√©rifier si le document est valide pour KIPIK
  bool get isValidForKIPIK {
    final validTypes = ['carte_identite', 'passeport', 'rib', 'kbis', 'certificat_hygiene'];
    return validTypes.contains(documentType) && confidence > 0.5;
  }
  
  /// Obtenir le nom d'affichage du document
  String get displayName {
    const displayNames = {
      'carte_identite': 'Carte d\'identit√©',
      'passeport': 'Passeport',
      'rib': 'RIB',
      'kbis': 'KBIS',
      'certificat_hygiene': 'Certificat d\'hygi√®ne',
    };
    return displayNames[documentType] ?? 'Document non identifi√©';
  }
}

/// Check de validation
class ValidationCheck {
  final String type;
  final bool passed;
  final String message;
  
  ValidationCheck(this.type, this.passed, this.message);
  
  bool get isCritical => type.contains('file_') || type.contains('text_content');
}

/// Type de document d√©tect√©
class _DocumentType {
  final String type;
  final double confidence;
  
  _DocumentType({required this.type, required this.confidence});
}